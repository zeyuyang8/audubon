{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solution for D2K Audubon project\n",
    "\n",
    "Create images for bird detection\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import utils.data_processing as dp\n",
    "import utils.data_vis as vis\n",
    "from utils.global_const import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Part 1 - Data processing\n",
    "\n",
    "def test_get_file_names():\n",
    "    ''' Test get_file_names() '''\n",
    "    csv_files = dp.get_file_names(DATA_PATH + 'raw/', 'csv')\n",
    "    jpg_files = dp.get_file_names(DATA_PATH + 'raw/', 'jpg')\n",
    "    FILES['dataset'] = {'jpg': jpg_files, 'csv': csv_files}\n",
    "\n",
    "test_get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_csv_to_df():\n",
    "    ''' Test csv_to_df() '''\n",
    "    file_name = FILES['dataset']['csv'][0]\n",
    "    data_df = dp.csv_to_df(file_name, COL_NAMES)\n",
    "    # print(data_df)\n",
    "    \n",
    "test_csv_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_concat_frames():\n",
    "    ''' Test concat_frames() ''' \n",
    "    concated_frame =  dp.concat_frames(FILES['dataset']['csv'], COL_NAMES)\n",
    "    # print(concated_frame)\n",
    "\n",
    "test_concat_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_add_col():\n",
    "    ''' Test add_col() '''\n",
    "    values_dict = {}\n",
    "    for key, vals in GROUPS.items():\n",
    "        for val in vals:\n",
    "            values_dict[val] = key\n",
    "    frame = dp.concat_frames(FILES['dataset']['csv'], COL_NAMES)\n",
    "    FRAMES['combined annotations'] = dp.add_col(frame, 'group_id', 'class_id', values_dict)\n",
    "    # print(FRAMES['combined annotations'])\n",
    "\n",
    "test_add_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_jpg():\n",
    "    ''' test read_jpg() '''\n",
    "    file_name = FILES['dataset']['jpg'][0]\n",
    "    dp.read_jpg(file_name)\n",
    "\n",
    "test_read_jpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Part 2 - Data visualization\n",
    "\n",
    "def test_plot_distribution():\n",
    "    ''' Test plot_distribution() ''' \n",
    "    vis.plot_distribution(FRAMES['combined annotations'], \"class_id\", \n",
    "                          (\"Frequency\", \"Bird Species\", \"Bird Species Distribution\"), PLOTS_PATH, filt=100)\n",
    "    vis.plot_distribution(FRAMES['combined annotations'], \"group_id\", \n",
    "                          (\"Frequency\", \"Bird Group\", \"Bird Group Distribution\"), PLOTS_PATH)\n",
    "    vis.plot_distribution(FRAMES['combined annotations'].loc[FRAMES['combined annotations']['group_id'] == 'BRPE'], \"class_id\", \n",
    "                          (\"Frequency\", \"Bird Species\", \"BRPE Bird Species Distribution\"), PLOTS_PATH)\n",
    "    vis.plot_distribution(FRAMES['combined annotations'].loc[FRAMES['combined annotations']['group_id'] == 'LGHT'], \"class_id\", \n",
    "                          (\"Frequency\", \"Bird Species\", \"LGHT Bird Species Distribution\"), PLOTS_PATH)            \n",
    "\n",
    "# test_plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_plot_boxes():\n",
    "    ''' Test plot_boxes() ''' \n",
    "    vis.plot_boxes(FILES['dataset']['jpg'][10], FILES['dataset']['csv'][10], 'Annonations', PLOTS_PATH)\n",
    "\n",
    "# test_plot_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Part 3 - Dataloader\n",
    "\n",
    "# Split the dataset into trainset, testset, and valset\n",
    "def test_split_img_annos():\n",
    "    ''' Test split_img_annos() '''\n",
    "    FILES['trainset'], FILES['testset'], FILES['valset'] = dp.split_img_annos(\n",
    "        FILES['dataset']['jpg'], FILES['dataset']['csv'], (0.8, 0.1, 0.1), seed=2023)\n",
    "\n",
    "test_split_img_annos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping\n",
    "# Make a dataloader\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from utils.data_loader import BirdDataset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our dataset and defined transformations\n",
    "trainset = BirdDataset(FILES['trainset'], F.to_tensor)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=2, shuffle=True, num_workers=4,\n",
    "    collate_fn=collate_fn # collate_fn is important otherwise it raises an error\n",
    ") \n",
    "\n",
    "testset = BirdDataset(FILES['testset'], F.to_tensor)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=collate_fn # collate_fn is important otherwise it raises an error\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# background and bird\n",
    "num_classes = 2\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "\n",
    "# construct an optimizer\n",
    "params = [param for param in model.parameters() if param.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, trainloader, testloader, n_epochs, device):\n",
    "    ''' Train a model '''\n",
    "    model = model.to(device)\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch:\", epoch)\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch, (images, targets) in enumerate(tqdm(trainloader, desc=f\"Epoch {epoch + 1} of {n_epochs}\", leave=True, ncols=80)):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{key: val.to(device) for key, val in target.items()} for target in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            print(\"Batch loss:\", losses)\n",
    "            epoch_loss += losses\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Loss:\", epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10:   0%|                                     | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: tensor(4.7048, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10:   1%|â–Ž                         | 1/80 [02:27<3:14:31, 147.75s/it]"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, trainloader, testloader, 10, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audubon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46beb778c8128495c73591d54954c8f1640826ad496c7f102ebbefec3a7b29b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
