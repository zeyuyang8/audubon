{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solution for D2K Audubon project\n",
    "\n",
    "Create images for bird detection\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import utils.data_processing as dp\n",
    "import utils.data_vis as vis\n",
    "from utils.global_const import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Part 1 - Data processing\n",
    "\n",
    "def test_get_file_names():\n",
    "    ''' Test get_file_names() '''\n",
    "    csv_files = dp.get_file_names(DATA_PATH + 'raw/', 'csv')\n",
    "    jpg_files = dp.get_file_names(DATA_PATH + 'raw/', 'jpg')\n",
    "    FILES['dataset'] = {'jpg': jpg_files, 'csv': csv_files}\n",
    "\n",
    "test_get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_csv_to_df():\n",
    "    ''' Test csv_to_df() '''\n",
    "    file_name = FILES['dataset']['csv'][0]\n",
    "    data_df = dp.csv_to_df(file_name, COL_NAMES)\n",
    "    # print(data_df)\n",
    "    \n",
    "test_csv_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_concat_frames():\n",
    "    ''' Test concat_frames() ''' \n",
    "    concated_frame =  dp.concat_frames(FILES['dataset']['csv'], COL_NAMES)\n",
    "    # print(concated_frame)\n",
    "\n",
    "test_concat_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_add_col():\n",
    "    ''' Test add_col() '''\n",
    "    values_dict = {}\n",
    "    for key, vals in GROUPS.items():\n",
    "        for val in vals:\n",
    "            values_dict[val] = key\n",
    "    frame = dp.concat_frames(FILES['dataset']['csv'], COL_NAMES)\n",
    "    FRAMES['combined annotations'] = dp.add_col(frame, 'group_id', 'class_id', values_dict)\n",
    "    # print(FRAMES['combined annotations'])\n",
    "\n",
    "test_add_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_jpg():\n",
    "    ''' test read_jpg() '''\n",
    "    file_name = FILES['dataset']['jpg'][0]\n",
    "    dp.read_jpg(file_name)\n",
    "\n",
    "test_read_jpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Part 2 - Data visualization\n",
    "\n",
    "def test_plot_distribution():\n",
    "    ''' Test plot_distribution() ''' \n",
    "    vis.plot_distribution(FRAMES['combined annotations'], \"class_id\", \n",
    "                          (\"Frequency\", \"Bird Species\", \"Bird Species Distribution\"), PLOTS_PATH, filt=100)\n",
    "    vis.plot_distribution(FRAMES['combined annotations'], \"group_id\", \n",
    "                          (\"Frequency\", \"Bird Group\", \"Bird Group Distribution\"), PLOTS_PATH)\n",
    "    vis.plot_distribution(FRAMES['combined annotations'].loc[FRAMES['combined annotations']['group_id'] == 'BRPE'], \"class_id\", \n",
    "                          (\"Frequency\", \"Bird Species\", \"BRPE Bird Species Distribution\"), PLOTS_PATH)\n",
    "    vis.plot_distribution(FRAMES['combined annotations'].loc[FRAMES['combined annotations']['group_id'] == 'LGHT'], \"class_id\", \n",
    "                          (\"Frequency\", \"Bird Species\", \"LGHT Bird Species Distribution\"), PLOTS_PATH)            \n",
    "\n",
    "# test_plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_plot_boxes():\n",
    "    ''' Test plot_boxes() ''' \n",
    "    vis.plot_boxes(FILES['dataset']['jpg'][10], FILES['dataset']['csv'][10], 'Annonations', PLOTS_PATH)\n",
    "\n",
    "# test_plot_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Part 3 - Dataloader\n",
    "\n",
    "# Split the dataset into trainset, testset, and valset\n",
    "def test_split_img_annos():\n",
    "    ''' Test split_img_annos() '''\n",
    "    FILES['trainset'], FILES['testset'], FILES['valset'] = dp.split_img_annos(\n",
    "        FILES['dataset']['jpg'], FILES['dataset']['csv'], (0.8, 0.1, 0.1), seed=2023)\n",
    "\n",
    "test_split_img_annos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping\n",
    "# Make a dataloader\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from utils.data_loader import BirdDataset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model\n",
    "# https://pytorch.org/vision/main/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn.html#torchvision.models.detection.fasterrcnn_resnet50_fpn\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "dataset = BirdDataset(FILES['dataset'], F.to_tensor)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=4,\n",
    "    collate_fn=collate_fn # collate_fn is important otherwise it raises an error\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training\n",
    "images, targets = next(iter(data_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(images, targets)   # Returns losses and detections\n",
    "# For inference\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([], dtype=torch.int64),\n",
       "  'scores': tensor([], grad_fn=<IndexBackward0>)},\n",
       " {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([], dtype=torch.int64),\n",
       "  'scores': tensor([], grad_fn=<IndexBackward0>)}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our dataset and defined transformations\n",
    "trainset = BirdDataset(FILES['trainset'], F.to_tensor)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=2, shuffle=True, num_workers=4,\n",
    "    collate_fn=collate_fn # collate_fn is important otherwise it raises an error\n",
    ") \n",
    "\n",
    "testset = BirdDataset(FILES['testset'], F.to_tensor)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=collate_fn # collate_fn is important otherwise it raises an error\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n",
    "    model.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    lr_scheduler = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "        lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
    "\n",
    "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    return metric_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's train it for 10 epochs\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, train_dataloader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, test_dataloader, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audubon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46beb778c8128495c73591d54954c8f1640826ad496c7f102ebbefec3a7b29b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
